{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsAlUd2Obhbd"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision opencv-python pycuda\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "# Load pre-trained VGG19 model\n",
        "model = vgg19(pretrained=True).features.eval()\n",
        "\n",
        "# Define transformations to preprocess the input image/frame\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "k-njB5xXbkhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU\n",
        "model = model.cuda()\n",
        "\n",
        "# Function to perform style transfer on a single frame\n",
        "def style_transfer(frame, model):\n",
        "    # Preprocess the frame and move to GPU\n",
        "    input_tensor = preprocess(frame).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_tensor = model(input_tensor)\n",
        "\n",
        "    # Post-process the output and move back to CPU\n",
        "    output_tensor = output_tensor.squeeze(0).cpu()\n",
        "    output_image = transforms.ToPILImage()(output_tensor)\n",
        "    return output_image\n"
      ],
      "metadata": {
        "id": "81NdNANFbuP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Initialize video capture (use 0 for webcam, or specify video file path)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to RGB (OpenCV uses BGR by default)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Apply the style transfer model\n",
        "    output_image = style_transfer(frame, model)\n",
        "\n",
        "    # Convert output image back to BGR for displaying\n",
        "    output_image = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display the output frame\n",
        "    cv2.imshow('Neural Style Transfer', output_image)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "nM5Pt-4_byDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Example CUDA kernel for a custom operation (e.g., element-wise multiplication)\n",
        "cuda_code = \"\"\"\n",
        "__global__ void elementwise_multiply(float *a, float *b, float *c, int n) {\n",
        "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] * b[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(cuda_code)\n",
        "multiply = mod.get_function(\"elementwise_multiply\")\n",
        "\n",
        "# Example function to use the CUDA kernel\n",
        "def gpu_multiply(a, b):\n",
        "    n = a.size\n",
        "    c = np.empty_like(a)\n",
        "\n",
        "    # Allocate GPU memory\n",
        "    a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "    c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "    # Copy data to GPU\n",
        "    cuda.memcpy_htod(a_gpu, a)\n",
        "    cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "    # Launch the kernel\n",
        "    block_size = 256\n",
        "    grid_size = (n + block_size - 1) // block_size\n",
        "    multiply(a_gpu, b_gpu, c_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "    # Copy the result back to CPU\n",
        "    cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "    return c\n"
      ],
      "metadata": {
        "id": "s3wi2LUNbzCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "for _ in range(100):  # Process 100 frames\n",
        "    _ = style_transfer(frame, model)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Processed 100 frames in {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "kl6wVF8Jb3cm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}